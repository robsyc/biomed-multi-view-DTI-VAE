{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Encoding drug-molecules\n",
    "\n",
    "Molecules in SMILES fromat are embedded through 3 views: MolGraph, Image, SMILES\n",
    "\n",
    "See\n",
    " - https://github.com/BiomedSciAI/biomed-multi-view\n",
    " - https://huggingface.co/ibm/biomed.sm.mv-te-84m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-04 21:22:36,815 - rdkit - INFO - pop-os:130600426774272:0:0 - Enabling RDKit 2024.03.5 jupyter extensions\n",
      "/home/robsyc/Desktop/thesis/biomed-multi-view-VAE/envs/biomed-multiview/lib/python3.11/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/home/robsyc/Desktop/thesis/biomed-multi-view-VAE/envs/biomed-multiview/lib/python3.11/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n",
      "  warnings.warn(msg)\n",
      "2024-11-04 21:22:37,865 - root - INFO - pop-os:130600426774272:0:0 - Using coeff_mlp architecture for aggregator\n",
      "2024-11-04 21:22:37,865 - root - INFO - pop-os:130600426774272:0:0 - dim_list [512, 512, 768] for aggregator\n",
      "2024-11-04 21:22:37,875 - root - INFO - pop-os:130600426774272:0:0 - Loading checkpoint from provided path ../data_root/bmfm_model_dir/pretrained/MULTIVIEW_MODEL/biomed-smmv-with-coeff-agg.pth\n",
      "2024-11-04 21:22:38,151 - root - INFO - pop-os:130600426774272:0:0 - Loading pretrain checkpoint for SmallMoleculeMultiView Model - <All keys matched successfully>\n",
      "2024-11-04 21:22:38,153 - root - INFO - pop-os:130600426774272:0:0 - in train False setting deterministic_eval = True\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from bmfm_sm.api.smmv_api import SmallMoleculeMultiViewModel\n",
    "from bmfm_sm.core.data_modules.namespace import LateFusionStrategy\n",
    "\n",
    "# model = torch.load('../data_root/bmfm_model_dir/pretrained/MULTIVIEW_MODEL/biomed-smmv-with-coeff-agg.pth')\n",
    "\n",
    "model_molecule = SmallMoleculeMultiViewModel.from_pretrained(\n",
    "    LateFusionStrategy.ATTENTIONAL,\n",
    "    model_path='../data_root/bmfm_model_dir/pretrained/MULTIVIEW_MODEL/biomed-smmv-with-coeff-agg.pth',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bmfm_sm.predictive.data_modules.graph_finetune_dataset import Graph2dFinetuneDataPipeline\n",
    "from bmfm_sm.predictive.data_modules.image_finetune_dataset import ImageFinetuneDataPipeline\n",
    "from bmfm_sm.predictive.data_modules.text_finetune_dataset import TextFinetuneDataPipeline\n",
    "\n",
    "some_smiles = [\n",
    "    'CC(C)CC1=CC=C(C=C1)C(C)C(=O)O',\n",
    "    'Cc1[nH]nc2ccc(-c3cncc(OCC(N)Cc4ccccc4)c3)cc12',\n",
    "    'CC(C)(C)c1cc(NC(=O)Nc2ccc(-c3cn4c(n3)sc3cc(OCCN5CCOCC5)ccc34)cc2)no1',\n",
    "    'CCN1CCN(Cc2ccc(NC(=O)Nc3ccc(Oc4cc(NC)ncn4)cc3)cc2C(F)(F)F)CC1',\n",
    "    'O=C(NC1CCNCC1)c1[nH]ncc1NC(=O)c1c(Cl)cccc1Cl',\n",
    "    'CN(C)CC=CC(=O)Nc1cc2c(Nc3ccc(F)c(Cl)c3)ncnc2cc1OC1CCOC1',\n",
    "    'CN1CCC(c2c(O)cc(O)c3c(=O)cc(-c4ccccc4Cl)oc23)C(O)C1',\n",
    "    'CNC(=O)c1ccccc1Sc1ccc2c(C=Cc3ccccn3)n[nH]c2c1',\n",
    "    'CCC1C(=O)N(C)c2cnc(Nc3ccc(C(=O)NC4CCN(C)CC4)cc3OC)nc2N1C1CCCC1',\n",
    "    'Cc1ccc2nc(NCCN)c3ncc(C)n3c2c1.Cl']\n",
    "\n",
    "smiles = some_smiles[2]\n",
    "graph = Graph2dFinetuneDataPipeline.smiles_to_graph_format(smiles)\n",
    "text = TextFinetuneDataPipeline.smiles_to_text_format(smiles)\n",
    "image = ImageFinetuneDataPipeline.smiles_to_image_format(smiles)\n",
    "\n",
    "joint_dict = {}\n",
    "joint_dict.update(graph)\n",
    "joint_dict.update(text)\n",
    "joint_dict.update(image)\n",
    "embedding = model_molecule.get_embeddings(joint_dict, get_separate_embeddings=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Graph2dModel embeddings shape: torch.Size([1, 512])\n",
      "ImageModel embeddings shape: torch.Size([1, 512])\n",
      "TextModel embeddings shape: torch.Size([1, 768])\n",
      "aggregator embeddings shape: torch.Size([1, 512])\n",
      "model_coeffs embeddings shape: torch.Size([3])\n"
     ]
    }
   ],
   "source": [
    "for view in embedding.keys():\n",
    "    print(f'{view} embeddings shape: {embedding[view].shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Encoding target-proteins\n",
    "\n",
    "Proteins in amino-acid sequence format are embedded through 1 view: amino-acid sequence\n",
    "\n",
    "See\n",
    " - https://github.com/mheinzinger/ProstT5\n",
    " - https://huggingface.co/Rostlab/ProstT5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.float32"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "from transformers import T5Tokenizer, T5EncoderModel\n",
    "import torch\n",
    "\n",
    "\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Load the tokenizer\n",
    "tokenizer = T5Tokenizer.from_pretrained('../data_root/ProstT5_model_dir', do_lower_case=False)\n",
    "\n",
    "# Load the model\n",
    "model_protein = T5EncoderModel.from_pretrained(\"../data_root/ProstT5_model_dir\").to(device)\n",
    "\n",
    "# only GPUs support half-precision (float16) currently; if you want to run on CPU use full-precision (float32) (not recommended, much slower)\n",
    "model_protein.float() if device.type=='cpu' else model_protein.half()\n",
    "model_protein.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch embedding:  torch.Size([5, 48, 1024]) \n",
      "\n",
      "Subsequence embedding:  torch.Size([46, 1024])\n",
      "Mean subsequence embedding:  torch.Size([1024]) \n",
      "\n",
      "Subsequence embedding:  torch.Size([36, 1024])\n",
      "Mean subsequence embedding:  torch.Size([1024]) \n",
      "\n",
      "Subsequence embedding:  torch.Size([28, 1024])\n",
      "Mean subsequence embedding:  torch.Size([1024]) \n",
      "\n",
      "Subsequence embedding:  torch.Size([17, 1024])\n",
      "Mean subsequence embedding:  torch.Size([1024]) \n",
      "\n",
      "Subsequence embedding:  torch.Size([10, 1024])\n",
      "Mean subsequence embedding:  torch.Size([1024]) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# prepare your protein sequences/structures as a list of upper-case amino acid sequences\n",
    "some_sequences = [\n",
    "    \"MKKFFDSRREQGGSGLGSGSSGGGGSTSGLGSGYIGRVFGIGRQQV\",\n",
    "    \"PFWKILNPLLERGTYYYFMGQQPGKVLGDQRRPSLP\",\n",
    "    \"MVLGTVLLPPNSYGRDQDTSLCCLCTEA\",\n",
    "    \"MVDGVMILPVLIMIALP\",\n",
    "    \"MGAAAKLAFA\",\n",
    "]\n",
    "# replace all rare/ambiguous amino acids by X and introduce white-space between all sequences\n",
    "sequences = [\" \".join(list(re.sub(r\"[UZOB]\", \"X\", sequence))).upper() for sequence in some_sequences]\n",
    "\n",
    "# indicate the direction of the translation by prepending \"<AA2fold>\" if you go from 3Di to AAs (or if you want to embed AAs)\n",
    "sequences = [\"<AA2fold>\" + \" \" + s for s in sequences]\n",
    "\n",
    "# tokenize sequences and pad up to the longest sequence in the batch\n",
    "ids = tokenizer.batch_encode_plus(sequences, add_special_tokens=True, padding=\"longest\", return_tensors='pt').to(device)\n",
    "\n",
    "\n",
    "# generate embeddings\n",
    "with torch.no_grad():\n",
    "    embeddings_rpr = model_protein(ids.input_ids,  attention_mask=ids.attention_mask).last_hidden_state\n",
    "print(\"Batch embedding: \", embeddings_rpr.shape, \"\\n\")\n",
    "\n",
    "# remove the special first token\n",
    "embeddings = []\n",
    "for i in range(embeddings_rpr.shape[0]):\n",
    "    l = len(some_sequences[i])\n",
    "    subseq = embeddings_rpr[i, 1:l+1]\n",
    "    print(\"Subsequence embedding: \", subseq.shape)\n",
    "    mean_subseq = subseq.mean(dim=0)\n",
    "    print(\"Mean subsequence embedding: \", mean_subseq.shape, \"\\n\")\n",
    "    embeddings.append(mean_subseq)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
